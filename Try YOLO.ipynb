{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonDScode/Fire_Detection/blob/main/Try%20YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qoIpfVCu9EM",
        "outputId": "ea7e5048-f743-42e0-b6f8-f8c93aa0872b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "HOME = \"/content\"\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalamos la biblioteca ultralytics y checkeamos las dependencias y configuraci√≥n."
      ],
      "metadata": {
        "id": "qzjPwMyT6-VM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5C4tosUvOeW",
        "outputId": "ba6c27cb-6b0d-4d37-aeab-2a0126bc0722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 24.1/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos algunas dependencias para mostrar im√°genes y trabajar con el modelo YOLO"
      ],
      "metadata": {
        "id": "fjeHwvbZ8H3j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BQ2v-MDhvPUX"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1FLH0Ifxm3G"
      },
      "source": [
        "Descargamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rk11bNH3vezf"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "!pip install roboflow\n",
        "\n",
        "%cd {HOME}\n",
        "!mkdir datasets\n",
        "%cd datasets\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"wTXiM0rKlGuZjFmG3WX0\")\n",
        "project = rf.workspace(\"custom-thxhn\").project(\"fire-wrpgm\")\n",
        "dataset = project.version(8).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta celda, se cambia el directorio de trabajo actual al directorio especificado por la variable HOME. Luego, se ejecuta el comando yolo para realizar la tarea de detecci√≥n utilizando el modo de entrenamiento (mode=train). Se especifica el modelo a utilizar como yolov8s.pt y se proporciona la ubicaci√≥n del archivo de configuraci√≥n de datos (data.yaml) mediante la variable dataset.location. Se configuran 25 √©pocas de entrenamiento (epochs=25) y se establece el tama√±o de imagen de entrada en 800 p√≠xeles (imgsz=800). Finalmente, se habilita la opci√≥n para generar gr√°ficos (plots=True)."
      ],
      "metadata": {
        "id": "n_9WUcT78SiQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTj2v5FYxpcF",
        "outputId": "f8ff762a-f860-43fb-c4f5-3d75bab702d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.yaml, data=/content/datasets/fire-8/data.yaml, epochs=25, patience=50, batch=16, imgsz=800, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/train2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 79.6MB/s]\n",
            "2023-06-22 09:28:18.996697: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-22 09:28:21.294531: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.Detect                [3, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11136761 parameters, 11136745 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/fire-8/train/labels... 877 images, 1 backgrounds, 0 corrupt: 100% 877/877 [00:00<00:00, 2137.71it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /content/datasets/fire-8/train/images/img_202_jpg.rf.def5560c0e7c53c30a7e4eed738c02cb.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/fire-8/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/fire-8/valid/labels... 47 images, 0 backgrounds, 0 corrupt: 100% 47/47 [00:00<00:00, 2006.50it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/fire-8/valid/labels.cache\n",
            "Image sizes 800 train, 800 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/55 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=800 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31gJFHqyx-Q_"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/results.png', width=600)"
      ],
      "metadata": {
        "id": "Amao9AW923ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)"
      ],
      "metadata": {
        "id": "t0GpuzAb3BI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta celda, se cambia el directorio de trabajo actual al directorio especificado por la variable HOME. Luego, se ejecuta el comando yolo para realizar la tarea de detecci√≥n en modo de predicci√≥n (mode=predict). Se especifica el modelo a utilizar como {HOME}/runs/detect/train/weights/best.pt, donde {HOME} es el directorio base. Se establece el umbral de confianza en 0.25 (conf=0.25). La fuente de las im√°genes de entrada se especifica como {dataset.location}/test/images, donde dataset.location es la ubicaci√≥n del conjunto de datos. Por √∫ltimo, se habilita la opci√≥n para guardar los resultados de detecci√≥n (save=True)."
      ],
      "metadata": {
        "id": "5ql4HXeA9bXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta celda, se cambia el directorio de trabajo actual al directorio especificado por la variable HOME. Luego, se ejecuta el comando yolo para realizar la tarea de detecci√≥n en modo de predicci√≥n (mode=predict). Se especifica el modelo a utilizar como {HOME}/runs/detect/train/weights/best.pt, donde {HOME} es el directorio base. Se establece el umbral de confianza en 0.25 (conf=0.25). La fuente de las im√°genes de entrada se especifica como {dataset.location}/test/images, donde dataset.location es la ubicaci√≥n del conjunto de datos. Por √∫ltimo, se habilita la opci√≥n para guardar los resultados de detecci√≥n (save=True)."
      ],
      "metadata": {
        "id": "NDSco0gi-Jiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True\n",
        "\n",
        "display.clear_output() #borra el display al terminar"
      ],
      "metadata": {
        "id": "_gZdG-CN3Me3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image_path in glob.glob(f'{HOME}/runs/detect/predict/*.jpg')[3:6]:\n",
        "      display(Image(filename=image_path, width=600))\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "OTXOM8603bVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source=/content/drive/MyDrive/forest-fire_5.mp4 save=True"
      ],
      "metadata": {
        "id": "SAWVzxOR3rp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "i3oLiG5f4zjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!kaggle datasets download -d alik05/forest-fire-dataset"
      ],
      "metadata": {
        "id": "V9NVxQv236ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "with zipfile.ZipFile(\"/content/forest-fire-dataset.zip\", 'r') as zip:\n",
        "  for member in tqdm(zip.infolist(), desc='Extrayendo '):\n",
        "    try:\n",
        "      zip.extract(member)\n",
        "    except zipfile.error as e:\n",
        "      pass"
      ],
      "metadata": {
        "id": "n_V0KC2a45Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a tratar de predecir ahora los fuegos y humos de un dataset de incendios forestales."
      ],
      "metadata": {
        "id": "XBolEM-z-UTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={HOME}/train-smoke save=True\n",
        "\n",
        "display.clear_output() #borra el display al terminar"
      ],
      "metadata": {
        "id": "lUmujiWK6MoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "from random import randint\n",
        "\n",
        "path = '/content/runs/detect/predict4'\n",
        "predicciones = os.listdir('/content/runs/detect/predict4')\n",
        "lista = []\n",
        "for i in range(5):\n",
        "  lista.append(randint(0, len(predicciones)))\n",
        "\n",
        "for i in lista:\n",
        "  image_path = path + '/' + predicciones[i]\n",
        "  display(Image(filename=image_path, width=600))\n",
        "\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "s1mTVoSc-jjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ksgT2JRJF5lU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWFtxyGoOkIDtDGY1321uj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}